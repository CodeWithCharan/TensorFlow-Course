{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIPD8TQ7x5gQ"
   },
   "source": [
    "## Sentiment Analysis\n",
    "Now, let's see a recurrent neural network in action through an example called \"sentiment analysis.\"\n",
    "\n",
    "Sentiment analysis is about using computers to figure out opinions in text. Specifically, it's about determining if a piece of writing, like a movie review, expresses a positive, negative, or neutral feeling toward something.\n",
    "\n",
    "For this example, we'll focus on classifying movie reviews into positive, negative, or neutral categories. It's a practical application of recurrent neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXBTUtfWy8Xv"
   },
   "source": [
    "### Movie Review Dataset\n",
    "Well start by loading in the IMDB movie review dataset from keras. This dataset contains 25,000 reviews from IMDB where each one is already preprocessed and has a label as either positive or negative. Each review is encoded by integers that represents how common a word is in the entire dataset. For example, a word encoded by the integer 3 means that it is the 3rd most common word in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVCNkPLX0AKj",
    "outputId": "f619061e-02f1-4f5b-c0a3-57f052ef9a98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
      "Collecting Keras-Preprocessing\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.23.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
      "Installing collected packages: Keras-Preprocessing\n",
      "Successfully installed Keras-Preprocessing-1.1.2\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
    "from keras.datasets import imdb\n",
    "!pip install Keras-Preprocessing\n",
    "from keras_preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCWRX82PasRn"
   },
   "outputs": [],
   "source": [
    "train_data[1] # Lets look at one review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq-fUG8Ua9OX"
   },
   "source": [
    "### More Preprocessing\n",
    "If we have a look at some of our loaded in reviews, we'll notice that they are different lengths. This is an issue. We cannot pass different length data into our neural network. Therefore, we must make each review the same length. To do this we will follow the procedure below:\n",
    "- if the review is greater than 250 words then trim off the extra words\n",
    "- if the review is less than 250 words add the necessary amount of 0's to make it equal to 250.\n",
    "\n",
    "Luckily for us keras has a function that can do this for us:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g144tiXDbymM"
   },
   "outputs": [],
   "source": [
    "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
    "test_data = sequence.pad_sequences(test_data, MAXLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdLvbCD_mDCh"
   },
   "source": [
    "### Creating the Model\n",
    "Now it's time to create the model. We'll use a **word embedding layer** as the first layer in our model and add a **LSTM layer** afterwards that feeds into a dense node to get our predicted sentiment.\n",
    "\n",
    "32 stands for the output dimension of the vectors generated by the embedding layer. We can change this value if we'd like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AeDIbPYBp_zD"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMWjeuRNqZEx",
    "outputId": "1d37bb79-3333-47d6-d4ad-faed339c1733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZClmujKqeCU"
   },
   "source": [
    "### Training\n",
    "Now it's time to compile and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1T7Q8x6ls-hX",
    "outputId": "45ed0e9e-e9c3-457b-ef20-5c6e841fd85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 71s 102ms/step - loss: 0.4738 - acc: 0.7699 - val_loss: 0.3339 - val_acc: 0.8594\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.2667 - acc: 0.8963 - val_loss: 0.3148 - val_acc: 0.8656\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 14s 22ms/step - loss: 0.2038 - acc: 0.9240 - val_loss: 0.3308 - val_acc: 0.8726\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.1648 - acc: 0.9401 - val_loss: 0.3374 - val_acc: 0.8736\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.1379 - acc: 0.9516 - val_loss: 0.3217 - val_acc: 0.8836\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.1149 - acc: 0.9610 - val_loss: 0.3167 - val_acc: 0.8830\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.0959 - acc: 0.9693 - val_loss: 0.3902 - val_acc: 0.8802\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.0803 - acc: 0.9752 - val_loss: 0.4811 - val_acc: 0.8668\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0694 - acc: 0.9780 - val_loss: 0.3696 - val_acc: 0.8846\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.0593 - acc: 0.9819 - val_loss: 0.4836 - val_acc: 0.8756\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EOenBu0tGPe"
   },
   "source": [
    "And we'll evaluate the model on our training data to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdRqkncStzEu",
    "outputId": "4971cb28-c3d6-4d58-a32f-90c8ecacf07f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.5716 - acc: 0.8528\n",
      "[0.5715908408164978, 0.852840006351471]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e50CECwNvyO3"
   },
   "source": [
    "So we're scoring somewhere in the mid-high 80's. Not bad for a simple recurrent network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNKnNUN5v4dL"
   },
   "source": [
    "###Making Predictions\n",
    "Now let’s use our network to make predictions on our own reviews.\n",
    "\n",
    "Since our reviews are encoded well need to convert any review that we write into that form so the network can understand it. To do that well load the encodings from the dataset and use them to encode our own data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSC7gvlmwBSh",
    "outputId": "e2330211-0482-4997-9792-8431c5e1a2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 1s 1us/step\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
     ]
    }
   ],
   "source": [
    "# Get the word index for the IMDb dataset\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "  # Convert the input text into a sequence of tokens\n",
    "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
    "\n",
    "  # Map tokens to their corresponding word index values (or 0 if not found)\n",
    "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "  return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
    "\n",
    "text = \"that movie was just amazing, so amazing\"\n",
    "encoded = encode_text(text)\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6RyVjoLxDCS",
    "outputId": "eb4ecb7e-1c0f-489b-827f-7f4d5ad73cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was just amazing so amazing\n"
     ]
    }
   ],
   "source": [
    "# while were at it lets make a decode function\n",
    "\n",
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "      if num != PAD:\n",
    "        text += reverse_word_index[num] + \" \"\n",
    "\n",
    "    return text[:-1]\n",
    "\n",
    "print(decode_integers(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqX29yRMxMHT",
    "outputId": "fb34af16-7dd6-42ee-92e3-e27560899511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 674ms/step\n",
      "[0.9660795]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[0.27064502]\n"
     ]
    }
   ],
   "source": [
    "# now time to make a prediction\n",
    "\n",
    "def predict(text):\n",
    "  encoded_text = encode_text(text)\n",
    "  pred = np.zeros((1,250))\n",
    "  pred[0] = encoded_text\n",
    "  result = model.predict(pred)\n",
    "  print(result[0])\n",
    "\n",
    "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
    "predict(negative_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wDiPrSmyEiw"
   },
   "source": [
    "The prediction results are as follows:\n",
    "\n",
    "- For the positive review: [0.9660795]\n",
    "- For the negative review: [0.27064502]\n",
    "\n",
    "Higher values indicate **\"positive review\"** and Lower values indicate **\"negative review\"** in the predicted sentiment."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
